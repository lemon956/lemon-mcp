#!/usr/bin/env python3
"""
Desktop File Analyzer MCP Server - æ¡Œé¢æ–‡ä»¶åˆ†æ MCP æœåŠ¡å™¨

è¿™ä¸ª MCP æœåŠ¡å™¨ä¸“é—¨ç”¨äºåˆ†ææ¡Œé¢ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œæä¾›æ–‡ä»¶ç±»å‹ç»Ÿè®¡ã€
æ–‡ä»¶ç®¡ç†å’Œæ–‡ä»¶å†…å®¹åˆ†æç­‰åŠŸèƒ½ï¼Œä¸“ä¸º Cursor ç¼–è¾‘å™¨ä¼˜åŒ–ã€‚
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List
import mimetypes
import platform

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("desktop-analyzer-mcp")


class DesktopAnalyzerMCPServer:
    """æ¡Œé¢æ–‡ä»¶åˆ†æ MCP æœåŠ¡å™¨"""

    def __init__(self):
        # è·å–æ¡Œé¢è·¯å¾„
        self.desktop_path = self._get_desktop_path()
        self.file_cache = {}
        self.last_scan_time = None

    def _get_desktop_path(self) -> str:
        """è·å–æ¡Œé¢ç›®å½•è·¯å¾„"""
        system = platform.system()

        if system == "Windows":
            desktop = os.path.join(os.path.expanduser("~"), "Desktop")
        elif system == "Darwin":  # macOS
            desktop = os.path.join(os.path.expanduser("~"), "Desktop")
        else:  # Linux
            # å°è¯•å¤šä¸ªå¯èƒ½çš„æ¡Œé¢ç›®å½•
            possible_paths = [
                os.path.join(os.path.expanduser("~"), "Desktop"),
                os.path.join(os.path.expanduser("~"), "æ¡Œé¢"),
                os.path.join(os.path.expanduser("~"), "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—"),
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    desktop = path
                    break
            else:
                desktop = os.path.expanduser("~")  # å¦‚æœæ‰¾ä¸åˆ°æ¡Œé¢ï¼Œä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½•

        return desktop

    def get_tools_definition(self):
        """è¿”å›å¯ç”¨çš„å·¥å…·å®šä¹‰"""
        return [
            {
                "name": "scan_desktop",
                "description": "æ‰«ææ¡Œé¢ç›®å½•ï¼Œè·å–æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "include_hidden": {
                            "type": "boolean",
                            "description": "æ˜¯å¦åŒ…å«éšè—æ–‡ä»¶",
                            "default": False
                        },
                        "max_depth": {
                            "type": "integer",
                            "description": "æ‰«ææ·±åº¦ï¼ˆ1=ä»…æ¡Œé¢ï¼Œ2=åŒ…å«ä¸€çº§å­ç›®å½•ï¼‰",
                            "default": 1,
                            "minimum": 1,
                            "maximum": 3
                        }
                    }
                }
            },
            {
                "name": "analyze_file_types",
                "description": "åˆ†ææ¡Œé¢æ–‡ä»¶ç±»å‹åˆ†å¸ƒ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "group_by": {
                            "type": "string",
                            "description": "åˆ†ç»„æ–¹å¼",
                            "enum": ["extension", "mimetype", "category"],
                            "default": "category"
                        }
                    }
                }
            },
            {
                "name": "get_file_details",
                "description": "è·å–ç‰¹å®šæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "filename": {
                            "type": "string",
                            "description": "æ–‡ä»¶åï¼ˆç›¸å¯¹äºæ¡Œé¢ç›®å½•ï¼‰"
                        }
                    },
                    "required": ["filename"]
                }
            },
            {
                "name": "find_large_files",
                "description": "æŸ¥æ‰¾æ¡Œé¢ä¸Šçš„å¤§æ–‡ä»¶",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "min_size_mb": {
                            "type": "number",
                            "description": "æœ€å°æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰",
                            "default": 10,
                            "minimum": 0.1
                        },
                        "limit": {
                            "type": "integer",
                            "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶",
                            "default": 10,
                            "minimum": 1,
                            "maximum": 50
                        }
                    }
                }
            },
            {
                "name": "find_duplicate_files",
                "description": "æŸ¥æ‰¾æ¡Œé¢ä¸Šå¯èƒ½é‡å¤çš„æ–‡ä»¶ï¼ˆåŸºäºæ–‡ä»¶åæ¨¡å¼ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "similarity_threshold": {
                            "type": "number",
                            "description": "ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰",
                            "default": 0.8,
                            "minimum": 0.1,
                            "maximum": 1.0
                        }
                    }
                }
            },
            {
                "name": "clean_desktop_suggestions",
                "description": "ç”Ÿæˆæ¡Œé¢æ¸…ç†å»ºè®®",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "analysis_type": {
                            "type": "string",
                            "description": "åˆ†æç±»å‹",
                            "enum": ["organization", "cleanup", "optimization"],
                            "default": "organization"
                        }
                    }
                }
            },
            {
                "name": "search_files",
                "description": "åœ¨æ¡Œé¢æœç´¢æ–‡ä»¶",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢å…³é”®è¯"
                        },
                        "file_type": {
                            "type": "string",
                            "description": "æ–‡ä»¶ç±»å‹è¿‡æ»¤",
                            "enum": ["all", "image", "document", "video", "audio", "archive", "executable"]
                        }
                    },
                    "required": ["query"]
                }
            },
            {
                "name": "get_desktop_stats",
                "description": "è·å–æ¡Œé¢ç»Ÿè®¡ä¿¡æ¯",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            }
        ]

    async def call_tool(self, name: str, arguments: dict) -> dict:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        try:
            if name == "scan_desktop":
                return await self._scan_desktop(arguments)
            elif name == "analyze_file_types":
                return await self._analyze_file_types(arguments)
            elif name == "get_file_details":
                return await self._get_file_details(arguments)
            elif name == "find_large_files":
                return await self._find_large_files(arguments)
            elif name == "find_duplicate_files":
                return await self._find_duplicate_files(arguments)
            elif name == "clean_desktop_suggestions":
                return await self._clean_desktop_suggestions(arguments)
            elif name == "search_files":
                return await self._search_files(arguments)
            elif name == "get_desktop_stats":
                return await self._get_desktop_stats(arguments)
            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥å·¥å…·: {name}",
                    "content": f"å·¥å…· '{name}' ä¸å­˜åœ¨"
                }
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨é”™è¯¯ {name}: {e}")
            return {
                "success": False,
                "error": str(e),
                "content": f"æ‰§è¡Œå·¥å…· '{name}' æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            }

    def _get_file_category(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ–‡ä»¶ç±»åˆ«"""
        ext = Path(file_path).suffix.lower()

        categories = {
            'image': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.svg', '.ico'],
            'document': ['.pdf', '.doc', '.docx', '.txt', '.rtf', '.odt', '.pages'],
            'spreadsheet': ['.xls', '.xlsx', '.csv', '.ods', '.numbers'],
            'presentation': ['.ppt', '.pptx', '.odp', '.key'],
            'video': ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v'],
            'audio': ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.wma', '.m4a'],
            'archive': ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz'],
            'executable': ['.exe', '.msi', '.app', '.deb', '.rpm', '.dmg'],
            'code': ['.py', '.js', '.html', '.css', '.java', '.cpp', '.c', '.php', '.rb', '.go'],
            'data': ['.json', '.xml', '.yaml', '.sql', '.db', '.sqlite']
        }

        for category, extensions in categories.items():
            if ext in extensions:
                return category

        return 'other'

    def _scan_directory(self, path: str, max_depth: int, current_depth: int = 1, include_hidden: bool = False) -> List[Dict]:
        """é€’å½’æ‰«æç›®å½•"""
        files = []

        try:
            for item in os.listdir(path):
                if not include_hidden and item.startswith('.'):
                    continue

                item_path = os.path.join(path, item)

                try:
                    stat = os.stat(item_path)
                    is_dir = os.path.isdir(item_path)

                    file_info = {
                        'name': item,
                        'path': item_path,
                        'relative_path': os.path.relpath(item_path, self.desktop_path),
                        'size': stat.st_size if not is_dir else 0,
                        'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        'is_directory': is_dir,
                        'depth': current_depth
                    }

                    if not is_dir:
                        file_info['extension'] = Path(item).suffix.lower()
                        file_info['category'] = self._get_file_category(item)
                        file_info['mimetype'] = mimetypes.guess_type(item)[
                            0] or 'unknown'

                    files.append(file_info)

                    # é€’å½’æ‰«æå­ç›®å½•
                    if is_dir and current_depth < max_depth:
                        files.extend(self._scan_directory(
                            item_path, max_depth, current_depth + 1, include_hidden))

                except (OSError, PermissionError) as e:
                    logger.warning(f"æ— æ³•è®¿é—® {item_path}: {e}")
                    continue

        except (OSError, PermissionError) as e:
            logger.error(f"æ— æ³•è¯»å–ç›®å½• {path}: {e}")

        return files

    async def _scan_desktop(self, arguments: dict) -> dict:
        """æ‰«ææ¡Œé¢ç›®å½•"""
        include_hidden = arguments.get("include_hidden", False)
        max_depth = arguments.get("max_depth", 1)

        if not os.path.exists(self.desktop_path):
            return {
                "success": False,
                "error": "æ¡Œé¢ç›®å½•ä¸å­˜åœ¨",
                "content": f"âŒ æ— æ³•æ‰¾åˆ°æ¡Œé¢ç›®å½•: {self.desktop_path}"
            }

        files = self._scan_directory(
            self.desktop_path, max_depth, include_hidden=include_hidden)
        self.file_cache = {f['relative_path']: f for f in files}
        self.last_scan_time = datetime.now()

        # ç»Ÿè®¡ä¿¡æ¯
        total_files = len([f for f in files if not f['is_directory']])
        total_dirs = len([f for f in files if f['is_directory']])
        total_size = sum(f['size'] for f in files if not f['is_directory'])

        result = f"""ğŸ“ æ¡Œé¢æ‰«æå®Œæˆï¼
        
ğŸ  æ¡Œé¢è·¯å¾„: {self.desktop_path}
ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
   â€¢ æ–‡ä»¶æ•°é‡: {total_files}
   â€¢ ç›®å½•æ•°é‡: {total_dirs}
   â€¢ æ€»å¤§å°: {self._format_size(total_size)}
   â€¢ æ‰«ææ·±åº¦: {max_depth}
   â€¢ åŒ…å«éšè—æ–‡ä»¶: {'æ˜¯' if include_hidden else 'å¦'}

ğŸ“‹ å‰ 10 ä¸ªæ–‡ä»¶:
"""

        for file in files[:10]:
            if file['is_directory']:
                result += f"   ğŸ“ {file['name']}/\n"
            else:
                size_str = self._format_size(file['size'])
                result += f"   ğŸ“„ {file['name']} ({size_str}) - {file['category']}\n"

        if len(files) > 10:
            result += f"   ... è¿˜æœ‰ {len(files) - 10} ä¸ªé¡¹ç›®"

        return {
            "success": True,
            "content": result
        }

    async def _analyze_file_types(self, arguments: dict) -> dict:
        """åˆ†ææ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
        group_by = arguments.get("group_by", "category")

        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        files = [f for f in self.file_cache.values() if not f['is_directory']]

        if group_by == "extension":
            groups = {}
            for file in files:
                ext = file.get('extension', 'æ— æ‰©å±•å')
                if ext not in groups:
                    groups[ext] = {'count': 0, 'size': 0}
                groups[ext]['count'] += 1
                groups[ext]['size'] += file['size']
        elif group_by == "mimetype":
            groups = {}
            for file in files:
                mime = file.get('mimetype', 'unknown')
                if mime not in groups:
                    groups[mime] = {'count': 0, 'size': 0}
                groups[mime]['count'] += 1
                groups[mime]['size'] += file['size']
        else:  # category
            groups = {}
            for file in files:
                cat = file.get('category', 'other')
                if cat not in groups:
                    groups[cat] = {'count': 0, 'size': 0}
                groups[cat]['count'] += 1
                groups[cat]['size'] += file['size']

        # æŒ‰æ–‡ä»¶æ•°é‡æ’åº
        sorted_groups = sorted(
            groups.items(), key=lambda x: x[1]['count'], reverse=True)

        result = f"ğŸ“Š æ–‡ä»¶ç±»å‹åˆ†æ (æŒ‰ {group_by} åˆ†ç»„):\n\n"

        for group_name, data in sorted_groups:
            percentage = (data['count'] / len(files)) * 100
            result += f"ğŸ”¸ {group_name}\n"
            result += f"   æ•°é‡: {data['count']} ({percentage:.1f}%)\n"
            result += f"   å¤§å°: {self._format_size(data['size'])}\n\n"

        return {
            "success": True,
            "content": result
        }

    async def _get_file_details(self, arguments: dict) -> dict:
        """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
        filename = arguments["filename"]

        file_path = os.path.join(self.desktop_path, filename)

        if not os.path.exists(file_path):
            return {
                "success": False,
                "error": "æ–‡ä»¶ä¸å­˜åœ¨",
                "content": f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}"
            }

        try:
            stat = os.stat(file_path)
            path_obj = Path(file_path)

            details = {
                "name": path_obj.name,
                "full_path": file_path,
                "size": stat.st_size,
                "created": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "accessed": datetime.fromtimestamp(stat.st_atime).isoformat(),
                "is_directory": os.path.isdir(file_path),
                "permissions": oct(stat.st_mode)[-3:],
            }

            if not details["is_directory"]:
                details["extension"] = path_obj.suffix.lower()
                details["category"] = self._get_file_category(file_path)
                details["mimetype"] = mimetypes.guess_type(file_path)[
                    0] or 'unknown'

            result = f"""ğŸ“„ æ–‡ä»¶è¯¦ç»†ä¿¡æ¯: {details['name']}

ğŸ“ è·¯å¾„: {details['full_path']}
ğŸ“ å¤§å°: {self._format_size(details['size'])}
ğŸ“… åˆ›å»ºæ—¶é—´: {details['created']}
ğŸ“ ä¿®æ”¹æ—¶é—´: {details['modified']}
ğŸ‘ï¸ è®¿é—®æ—¶é—´: {details['accessed']}
ğŸ”’ æƒé™: {details['permissions']}
ğŸ“ ç±»å‹: {'ç›®å½•' if details['is_directory'] else 'æ–‡ä»¶'}
"""

            if not details["is_directory"]:
                result += f"""ğŸ·ï¸ æ‰©å±•å: {details['extension'] or 'æ— '}
ğŸ“‚ ç±»åˆ«: {details['category']}
ğŸ­ MIMEç±»å‹: {details['mimetype']}"""

            return {
                "success": True,
                "content": result
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "content": f"âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}"
            }

    async def _find_large_files(self, arguments: dict) -> dict:
        """æŸ¥æ‰¾å¤§æ–‡ä»¶"""
        min_size_mb = arguments.get("min_size_mb", 10)
        limit = arguments.get("limit", 10)

        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        min_size_bytes = min_size_mb * 1024 * 1024
        large_files = [
            f for f in self.file_cache.values()
            if not f['is_directory'] and f['size'] >= min_size_bytes
        ]

        # æŒ‰å¤§å°æ’åº
        large_files.sort(key=lambda x: x['size'], reverse=True)
        large_files = large_files[:limit]

        if not large_files:
            return {
                "success": True,
                "content": f"âœ… æ²¡æœ‰æ‰¾åˆ°å¤§äº {min_size_mb}MB çš„æ–‡ä»¶"
            }

        result = f"ğŸ˜ æ‰¾åˆ° {len(large_files)} ä¸ªå¤§æ–‡ä»¶ (>{min_size_mb}MB):\n\n"

        for i, file in enumerate(large_files, 1):
            result += f"{i}. ğŸ“„ {file['name']}\n"
            result += f"   å¤§å°: {self._format_size(file['size'])}\n"
            result += f"   ç±»å‹: {file['category']}\n"
            result += f"   è·¯å¾„: {file['relative_path']}\n\n"

        total_size = sum(f['size'] for f in large_files)
        result += f"ğŸ’¾ æ€»è®¡å¤§å°: {self._format_size(total_size)}"

        return {
            "success": True,
            "content": result
        }

    async def _find_duplicate_files(self, arguments: dict) -> dict:
        """æŸ¥æ‰¾å¯èƒ½é‡å¤çš„æ–‡ä»¶"""
        similarity_threshold = arguments.get("similarity_threshold", 0.8)

        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        files = [f for f in self.file_cache.values() if not f['is_directory']]
        duplicates = []

        # ç®€å•çš„åŸºäºæ–‡ä»¶åç›¸ä¼¼åº¦çš„é‡å¤æ£€æµ‹
        for i, file1 in enumerate(files):
            for file2 in files[i+1:]:
                # è®¡ç®—æ–‡ä»¶åç›¸ä¼¼åº¦ï¼ˆç®€å•çš„å­—ç¬¦åŒ¹é…ï¼‰
                name1 = Path(file1['name']).stem.lower()
                name2 = Path(file2['name']).stem.lower()

                if name1 == name2:
                    similarity = 1.0
                else:
                    # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
                    common_chars = set(name1) & set(name2)
                    total_chars = set(name1) | set(name2)
                    similarity = len(common_chars) / \
                        len(total_chars) if total_chars else 0

                if similarity >= similarity_threshold:
                    duplicates.append({
                        'file1': file1,
                        'file2': file2,
                        'similarity': similarity
                    })

        if not duplicates:
            return {
                "success": True,
                "content": f"âœ… æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦å¤§äº {similarity_threshold:.0%} çš„é‡å¤æ–‡ä»¶"
            }

        result = f"ğŸ” æ‰¾åˆ° {len(duplicates)} ç»„å¯èƒ½é‡å¤çš„æ–‡ä»¶:\n\n"

        for i, dup in enumerate(duplicates, 1):
            result += f"{i}. ç›¸ä¼¼åº¦: {dup['similarity']:.0%}\n"
            result += f"   ğŸ“„ {dup['file1']['name']} ({self._format_size(dup['file1']['size'])})\n"
            result += f"   ğŸ“„ {dup['file2']['name']} ({self._format_size(dup['file2']['size'])})\n\n"

        return {
            "success": True,
            "content": result
        }

    async def _clean_desktop_suggestions(self, arguments: dict) -> dict:
        """ç”Ÿæˆæ¡Œé¢æ¸…ç†å»ºè®®"""
        analysis_type = arguments.get("analysis_type", "organization")

        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        files = [f for f in self.file_cache.values() if not f['is_directory']]

        if analysis_type == "organization":
            # æŒ‰ç±»åˆ«åˆ†ç»„å»ºè®®
            categories = {}
            for file in files:
                cat = file['category']
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(file)

            result = "ğŸ“‹ æ¡Œé¢æ•´ç†å»ºè®®:\n\n"

            for category, cat_files in categories.items():
                if len(cat_files) > 2:  # åªå¯¹æœ‰å¤šä¸ªæ–‡ä»¶çš„ç±»åˆ«æä¾›å»ºè®®
                    result += f"ğŸ“ å»ºè®®åˆ›å»º '{category}' æ–‡ä»¶å¤¹ï¼Œç§»å…¥ {len(cat_files)} ä¸ªæ–‡ä»¶:\n"
                    for file in cat_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        result += f"   â€¢ {file['name']}\n"
                    if len(cat_files) > 5:
                        result += f"   ... è¿˜æœ‰ {len(cat_files) - 5} ä¸ªæ–‡ä»¶\n"
                    result += "\n"

        elif analysis_type == "cleanup":
            # æ¸…ç†å»ºè®®
            large_files = [f for f in files if f['size']
                           > 50 * 1024 * 1024]  # >50MB
            old_files = []

            # æŸ¥æ‰¾æ—§æ–‡ä»¶ï¼ˆè¶…è¿‡30å¤©æœªä¿®æ”¹ï¼‰
            now = datetime.now()
            for file in files:
                modified = datetime.fromisoformat(file['modified'])
                if (now - modified).days > 30:
                    old_files.append(file)

            result = "ğŸ§¹ æ¡Œé¢æ¸…ç†å»ºè®®:\n\n"

            if large_files:
                result += f"ğŸ˜ å¤§æ–‡ä»¶æ¸…ç† ({len(large_files)} ä¸ªæ–‡ä»¶):\n"
                for file in large_files[:5]:
                    result += f"   â€¢ {file['name']} - {self._format_size(file['size'])}\n"
                result += "\n"

            if old_files:
                result += f"ğŸ“… æ—§æ–‡ä»¶æ¸…ç† ({len(old_files)} ä¸ªæ–‡ä»¶):\n"
                for file in old_files[:5]:
                    days_old = (
                        now - datetime.fromisoformat(file['modified'])).days
                    result += f"   â€¢ {file['name']} - {days_old} å¤©å‰ä¿®æ”¹\n"
                result += "\n"

        else:  # optimization
            result = "âš¡ æ¡Œé¢ä¼˜åŒ–å»ºè®®:\n\n"

            total_files = len(files)
            if total_files > 20:
                result += f"ğŸ“Š æ¡Œé¢æ–‡ä»¶è¿‡å¤š ({total_files} ä¸ª)ï¼Œå»ºè®®æ•´ç†\n\n"

            # ç»Ÿè®¡å„ç±»å‹æ–‡ä»¶
            categories = {}
            for file in files:
                cat = file['category']
                categories[cat] = categories.get(cat, 0) + 1

            result += "ğŸ“ˆ æ–‡ä»¶ç±»å‹åˆ†å¸ƒå»ºè®®:\n"
            for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                if count > 3:
                    result += f"   â€¢ {cat}: {count} ä¸ªæ–‡ä»¶ - å»ºè®®åˆ†ç±»æ•´ç†\n"

        return {
            "success": True,
            "content": result
        }

    async def _search_files(self, arguments: dict) -> dict:
        """æœç´¢æ–‡ä»¶"""
        query = arguments["query"].lower()
        file_type = arguments.get("file_type", "all")

        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        files = [f for f in self.file_cache.values() if not f['is_directory']]

        # æŒ‰æ–‡ä»¶ç±»å‹è¿‡æ»¤
        if file_type != "all":
            type_mapping = {
                "image": "image",
                "document": ["document", "spreadsheet", "presentation"],
                "video": "video",
                "audio": "audio",
                "archive": "archive",
                "executable": "executable"
            }

            if file_type in type_mapping:
                allowed_categories = type_mapping[file_type]
                if isinstance(allowed_categories, str):
                    allowed_categories = [allowed_categories]
                files = [f for f in files if f['category']
                         in allowed_categories]

        # æœç´¢åŒ¹é…
        matches = []
        for file in files:
            if query in file['name'].lower():
                matches.append(file)

        if not matches:
            return {
                "success": True,
                "content": f"ğŸ” æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{query}' çš„æ–‡ä»¶"
            }

        result = f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {len(matches)} ä¸ªæ–‡ä»¶:\n\n"

        for i, file in enumerate(matches[:20], 1):  # é™åˆ¶æ˜¾ç¤º20ä¸ªç»“æœ
            result += f"{i}. ğŸ“„ {file['name']}\n"
            result += f"   å¤§å°: {self._format_size(file['size'])}\n"
            result += f"   ç±»å‹: {file['category']}\n"
            result += f"   è·¯å¾„: {file['relative_path']}\n\n"

        if len(matches) > 20:
            result += f"... è¿˜æœ‰ {len(matches) - 20} ä¸ªåŒ¹é…æ–‡ä»¶"

        return {
            "success": True,
            "content": result
        }

    async def _get_desktop_stats(self, arguments: dict) -> dict:
        """è·å–æ¡Œé¢ç»Ÿè®¡ä¿¡æ¯"""
        if not self.file_cache:
            return {
                "success": False,
                "error": "è¯·å…ˆæ‰«ææ¡Œé¢",
                "content": "âŒ è¯·å…ˆä½¿ç”¨ scan_desktop å·¥å…·æ‰«ææ¡Œé¢"
            }

        files = [f for f in self.file_cache.values() if not f['is_directory']]
        dirs = [f for f in self.file_cache.values() if f['is_directory']]

        # åŸºæœ¬ç»Ÿè®¡
        total_files = len(files)
        total_dirs = len(dirs)
        total_size = sum(f['size'] for f in files)

        # ç±»åˆ«ç»Ÿè®¡
        categories = {}
        for file in files:
            cat = file['category']
            categories[cat] = categories.get(cat, 0) + 1

        # å¤§å°ç»Ÿè®¡
        size_ranges = {
            "< 1KB": 0,
            "1KB - 1MB": 0,
            "1MB - 10MB": 0,
            "10MB - 100MB": 0,
            "> 100MB": 0
        }

        for file in files:
            size = file['size']
            if size < 1024:
                size_ranges["< 1KB"] += 1
            elif size < 1024 * 1024:
                size_ranges["1KB - 1MB"] += 1
            elif size < 10 * 1024 * 1024:
                size_ranges["1MB - 10MB"] += 1
            elif size < 100 * 1024 * 1024:
                size_ranges["10MB - 100MB"] += 1
            else:
                size_ranges["> 100MB"] += 1

        result = f"""ğŸ“Š æ¡Œé¢ç»Ÿè®¡æŠ¥å‘Š
        
ğŸ  æ¡Œé¢è·¯å¾„: {self.desktop_path}
ğŸ“… æœ€åæ‰«æ: {self.last_scan_time.strftime('%Y-%m-%d %H:%M:%S') if self.last_scan_time else 'æœªçŸ¥'}

ğŸ“ åŸºæœ¬ç»Ÿè®¡:
   â€¢ æ–‡ä»¶æ€»æ•°: {total_files}
   â€¢ ç›®å½•æ€»æ•°: {total_dirs}
   â€¢ æ€»å¤§å°: {self._format_size(total_size)}
   â€¢ å¹³å‡æ–‡ä»¶å¤§å°: {self._format_size(total_size / total_files) if total_files > 0 else '0 B'}

ğŸ“‚ æ–‡ä»¶ç±»åˆ«åˆ†å¸ƒ:
"""

        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total_files) * 100 if total_files > 0 else 0
            result += f"   â€¢ {category}: {count} ({percentage:.1f}%)\n"

        result += "\nğŸ“ æ–‡ä»¶å¤§å°åˆ†å¸ƒ:\n"
        for size_range, count in size_ranges.items():
            percentage = (count / total_files) * 100 if total_files > 0 else 0
            result += f"   â€¢ {size_range}: {count} ({percentage:.1f}%)\n"

        return {
            "success": True,
            "content": result
        }

    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"

        units = ['B', 'KB', 'MB', 'GB', 'TB']
        size = float(size_bytes)
        unit_index = 0

        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1

        if unit_index == 0:
            return f"{int(size)} {units[unit_index]}"
        else:
            return f"{size:.1f} {units[unit_index]}"


# MCP åè®®å¤„ç†
def create_mcp_response(request_id: str, result: Any) -> str:
    """åˆ›å»º MCP å“åº”"""
    response = {
        "jsonrpc": "2.0",
        "id": request_id,
        "result": result
    }
    return json.dumps(response)


def create_mcp_error(request_id: str, code: int, message: str) -> str:
    """åˆ›å»º MCP é”™è¯¯å“åº”"""
    response = {
        "jsonrpc": "2.0",
        "id": request_id,
        "error": {
            "code": code,
            "message": message
        }
    }
    return json.dumps(response)


async def handle_mcp_request(server: DesktopAnalyzerMCPServer, request: dict) -> str:
    """å¤„ç† MCP è¯·æ±‚"""
    request_id = request.get("id")
    method = request.get("method")
    params = request.get("params", {})

    try:
        if method == "initialize":
            result = {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "tools": {
                        "listChanged": True
                    }
                },
                "serverInfo": {
                    "name": "desktop-analyzer-mcp",
                    "version": "1.0.0"
                }
            }
            return create_mcp_response(request_id, result)

        elif method == "tools/list":
            tools = server.get_tools_definition()
            result = {"tools": tools}
            return create_mcp_response(request_id, result)

        elif method == "tools/call":
            tool_name = params.get("name")
            arguments = params.get("arguments", {})

            tool_result = await server.call_tool(tool_name, arguments)

            result = {
                "content": [
                    {
                        "type": "text",
                        "text": tool_result.get("content", "")
                    }
                ],
                "isError": not tool_result.get("success", False)
            }
            return create_mcp_response(request_id, result)

        else:
            return create_mcp_error(request_id, -32601, f"æœªçŸ¥æ–¹æ³•: {method}")

    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return create_mcp_error(request_id, -32603, f"å†…éƒ¨é”™è¯¯: {str(e)}")


async def main():
    """ä¸»å‡½æ•° - å¯åŠ¨ stdio MCP æœåŠ¡å™¨"""
    server = DesktopAnalyzerMCPServer()
    logger.info(f"ğŸš€ å¯åŠ¨æ¡Œé¢åˆ†æ MCP Server... (æ¡Œé¢è·¯å¾„: {server.desktop_path})")

    try:
        while True:
            # ä»æ ‡å‡†è¾“å…¥è¯»å–è¯·æ±‚
            line = sys.stdin.readline()
            if not line:
                break

            try:
                request = json.loads(line.strip())
                logger.info(f"è¯·æ±‚: {request}")
                response = await handle_mcp_request(server, request)
                print(response, flush=True)
            except json.JSONDecodeError:
                logger.error(f"æ— æ•ˆçš„ JSON è¯·æ±‚: {line}")
            except Exception as e:
                logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    except KeyboardInterrupt:
        logger.info("æœåŠ¡å™¨å·²åœæ­¢")


if __name__ == "__main__":
    asyncio.run(main())
